{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DVL7_bgmIAPR"
   },
   "source": [
    "# K-Nearest Neighbor Lab\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "metadata": {
    "id": "6ZbYjZZZ_yLV"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import time as time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# so I don't get a future warning cropping up each time. \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sCcEPx5VIORj"
   },
   "source": [
    "## 1. (40%) Correctly implement the k-nearest neighbor (KNN) algorithm and the KNN regression algorithm\n",
    "\n",
    "### Code requirements\n",
    "- Use Euclidean distance to decide closest neighbors. \n",
    "- Include optional distance weighting for both algorithms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {
    "id": "_a2KSZ_7AN0G"
   },
   "outputs": [],
   "source": [
    "class KNNClassifier(BaseEstimator,ClassifierMixin):\n",
    "    def __init__(self, K, columntype=[], weight_type='inverse_distance', metric = \"2_norm\"): ## add parameters here\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            columntype for each column tells you if continues[real] or if nominal[categoritcal].\n",
    "            weight_type: inverse_distance voting or if non distance weighting. Options = [\"no_weight\",\"inverse_distance\"]\n",
    "        \"\"\"\n",
    "        self.columntype = columntype #Note This won't be needed until part 5\n",
    "        self.weight_type = weight_type\n",
    "        self.K = K\n",
    "        self.metric = metric\n",
    "\n",
    "    def fit(self, X, y, normalize = False, regression = False):\n",
    "        \"\"\" Fit the data; run the algorithm (for this lab really just saves the data :D)\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the training data, excluding targets\n",
    "            y (array-like): A 2D numpy array with the training targets\n",
    "        Returns:\n",
    "            self: this allows this to be chained, e.g. model.fit(X,y).predict(X_test)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.regression = regression\n",
    "        if normalize:\n",
    "            self.X_train = self.normalize_dataset(X.values)\n",
    "            self.y_train = y.values\n",
    "        else:\n",
    "            self.X_train = X.values # Data\n",
    "            self.y_train = y.values # Labels\n",
    "        \n",
    "        \n",
    "        self.normalize = normalize\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict all classes for a dataset X\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with the testing data, excluding targets\n",
    "        Returns:\n",
    "            array, shape (n_samples,)\n",
    "                Predicted target values per element in X.\n",
    "        \"\"\"\n",
    "        all_labels = list(set(self.y_train))\n",
    "        X_test = X.values\n",
    "        \n",
    "        preds = []\n",
    "        labels = dict()\n",
    "        \n",
    "        if self.normalize:\n",
    "            X_test = self.normalize_dataset(X_test)\n",
    "        \n",
    "        for test in X_test:\n",
    "            distances = dict()\n",
    "            if self.metric == \"2_norm\":\n",
    "                norms = np.linalg.norm(test - self.X_train, axis = 1)\n",
    "                \n",
    "            elif self.metric == \"custom\":\n",
    "                norms = []\n",
    "                for row in self.X_train:\n",
    "                    norm = 0\n",
    "                    for j in range(len(row)):\n",
    "                        if row[j] == None or test[j] == None:\n",
    "                            norm += 1\n",
    "                        elif isinstance(row[j], float):\n",
    "                            if row[j] != test[j]:\n",
    "                                a = row[j]/(row[j] + test[j])\n",
    "                                b = test[j]/(row[j] + test[j])\n",
    "                                norm += np.linalg.norm(a - b)\n",
    "                        elif isinstance(row[j], bytes):\n",
    "                            if row[j] != test[j]:\n",
    "                                norm += 1\n",
    "                    \n",
    "                    norms.append(norm)\n",
    "            \n",
    "            for i in range(len(norms)):\n",
    "                distances[i] = norms[i]\n",
    "            sorted_distances = sorted(distances.items(), key = lambda x: x[1]) # sort by norm\n",
    "            \n",
    "            closest_labels = dict() # maps norm to label\n",
    "            inds = [i[0] for i in sorted_distances[:self.K]]\n",
    "            norm = [i[1] for i in sorted_distances[:self.K]]\n",
    "            for i,n in zip(inds, norm):\n",
    "                closest_labels[n] = self.y_train[i]\n",
    "            \n",
    "            \n",
    "            if self.regression:\n",
    "                 # ------Weighted------\n",
    "                if self.weight_type == \"inverse_distance\":\n",
    "                    # sum of 1/distance**2 * regression label) / sum of 1/distance**2 for all neighbors\n",
    "                    numer = sum([closest_labels[d]/(d**2) for d in closest_labels.keys()])\n",
    "                    denom = sum([1 / (d**2) for d in closest_labels.keys()])\n",
    "                    preds.append(numer / denom)\n",
    "                \n",
    "                \n",
    "                \n",
    "                # ------Not Weighted------\n",
    "                elif self.weight_type == \"no_weight\":\n",
    "                    # average label of neighbors:\n",
    "                    labels = list(closest_labels.values())\n",
    "                    preds.append(np.mean(labels))\n",
    "                \n",
    "            else: # Classification case\n",
    "                # ------Weighted------\n",
    "                if self.weight_type == \"inverse_distance\":\n",
    "                    inv_closest_labels = {(1 / (d**2)): closest_labels[d] for d in closest_labels.keys()} # Maps 1/norm^2 to label\n",
    "                    labels = set(inv_closest_labels.values())\n",
    "\n",
    "\n",
    "                    counts = dict() # Maps label to sum\n",
    "\n",
    "                    for l in labels:\n",
    "                        s = 0\n",
    "                        for key, val in inv_closest_labels.items():\n",
    "                            if val == l:\n",
    "                                s += key\n",
    "                        counts[l] = s\n",
    "\n",
    "                    preds.append(max(counts, key=counts.get))\n",
    "\n",
    "                # ------Not Weighted------\n",
    "                elif self.weight_type == \"no_weight\":\n",
    "                    # If all 3 closest neighbors have different labels, choose the label of the closest point\n",
    "                    if len(set(closest_labels.values())) == 3:\n",
    "                        preds.append(list(closest_labels.values())[0])\n",
    "\n",
    "                    # Otherwise, just choose the label that appears most often among 3 closest neighbors\n",
    "                    else:\n",
    "                        counts = [list(closest_labels.values()).count(l) for l in all_labels]\n",
    "                        preds.append(all_labels[np.argmax(counts)])\n",
    "                    \n",
    "        return preds\n",
    "       \n",
    "\n",
    "\n",
    "    #Returns the Mean score given input data and labels\n",
    "    def score(self, X, y):\n",
    "        \"\"\" Return accuracy of model on a given dataset. Must implement own score function.\n",
    "        Args:\n",
    "            X (array-like): A 2D numpy array with data, excluding targets\n",
    "            y (array-like): A 2D numpy array with targets\n",
    "        Returns:\n",
    "            score : float\n",
    "                Mean accuracy of self.predict(X) wrt. y.\n",
    "        \"\"\"\n",
    "        if self.regression:\n",
    "            return np.mean([(self.predict(X)[i] - y.values[i])**2 for i in range(len(y.values))])\n",
    "        \n",
    "        \n",
    "        else:\n",
    "            count = 0\n",
    "\n",
    "            for p,t in zip(self.predict(X), y.values):\n",
    "                if p == t:\n",
    "                    count += 1\n",
    "            return count / len(y.values)\n",
    "    \n",
    "    \n",
    "    # Helper functions for normalizing the data\n",
    "    def dataset_minmax(self, dataset):\n",
    "        minmax = list()\n",
    "        for i in range(len(dataset[0])):\n",
    "            col_values = [row[i] for row in dataset]\n",
    "            value_min = min(col_values)\n",
    "            value_max = max(col_values)\n",
    "            minmax.append([value_min, value_max])\n",
    "        return minmax\n",
    "    \n",
    "    def normalize_dataset(self, dataset):\n",
    "        minmax = self.dataset_minmax(dataset)\n",
    "        for row in dataset:\n",
    "            for i in range(len(row)):\n",
    "                row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])\n",
    "        return dataset\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Debug and Evaluation\n",
    "\n",
    "Debug and Evaluate your model using the parameters below:\n",
    "\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "---\n",
    "\n",
    "### 1.1.1 Debug\n",
    "\n",
    "- Use this [glass training set](https://byu.instructure.com/courses/14142/files?preview=4660939) and this [glass test set](https://byu.instructure.com/courses/14142/files?preview=4660941)\n",
    "- Use distance weighting\n",
    "- KNN = 3 (three nearest neighbors)\n",
    "- Don’t normalize the data\n",
    "- Use Euclidean Distance\n",
    "\n",
    "Expected Results:\n",
    "- Not using inverse weighted distancing = roughly [68.29%]\n",
    "- Link to [glass no_inverse debug solution](https://byu.instructure.com/courses/14142/files?preview=4660947)\n",
    "\n",
    "- Using inverse weighted distancing = roughly [74.39%]\n",
    "- Link to [glass inverse debug solution](https://byu.instructure.com/courses/14142/files?preview=4660954)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy not using inverse weighting: \n",
      "\t71.9512%\n",
      "\n",
      "Accuracy using inverse weighting: \n",
      "\t74.3902%\n"
     ]
    }
   ],
   "source": [
    "# Load glass data\n",
    "debug_data_train = arff.loadarff('glass_train.arff')\n",
    "debug_df_train = pd.DataFrame(debug_data_train[0])\n",
    "\n",
    "features_train = list(debug_df_train.columns)\n",
    "X_train = debug_df_train[features_train[0:-1]]\n",
    "y_train = debug_df_train[features_train[-1]]\n",
    "\n",
    "debug_data_test = arff.loadarff('glass_test.arff')\n",
    "debug_df_test = pd.DataFrame(debug_data_test[0])\n",
    "\n",
    "features_test = list(debug_df_test.columns)\n",
    "X_test = debug_df_test[features_test[0:-1]]\n",
    "y_test = debug_df_test[features_test[-1]]\n",
    "\n",
    "# ------------No weight------------\n",
    "# Train on training set\n",
    "knn = KNNClassifier(K = 3, weight_type = \"no_weight\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "# knn.predict(X_test)\n",
    "print(f\"Accuracy not using inverse weighting: \\n\\t{np.round(100*knn.score(X_test, y_test), 4)}%\")\n",
    "print(\"\")\n",
    "# # ------------Using inverse_distance------------\n",
    "# # Train on training set\n",
    "knn = KNNClassifier(K = 3, weight_type = \"inverse_distance\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "# knn.predict(X_test)\n",
    "print(f\"Accuracy using inverse weighting: \\n\\t{np.round(100*knn.score(X_test, y_test), 4)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.2 Evaluate\n",
    "\n",
    "We will evaluate your model based on its performance on the [diabetes](https://archive.ics.uci.edu/ml/datasets/Diabetes) problem.\n",
    "- Use this [diabetes training set](https://byu.instructure.com/courses/14142/files?preview=4660977) and this [diabetes test set](https://byu.instructure.com/courses/14142/files?preview=4660978)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using inverse weighting: \n",
      "\t89.0625%\n"
     ]
    }
   ],
   "source": [
    "# Load diabetes data\n",
    "eval_data_train = arff.loadarff('diabetes_train.arff')\n",
    "eval_df_train = pd.DataFrame(eval_data_train[0])\n",
    "\n",
    "features_train = list(eval_df_train.columns)\n",
    "X_train = eval_df_train[features_train[0:-1]]\n",
    "y_train = eval_df_train[features_train[-1]]\n",
    "\n",
    "eval_data_test = arff.loadarff('diabetes_test.arff')\n",
    "eval_df_test = pd.DataFrame(eval_data_test[0])\n",
    "\n",
    "features_test = list(eval_df_test.columns)\n",
    "X_test = eval_df_test[features_test[0:-1]]\n",
    "y_test = eval_df_test[features_test[-1]]\n",
    "\n",
    "# Train on training set\n",
    "knn = KNNClassifier(K = 3, weight_type = \"inverse_distance\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "knn.predict(X_test)\n",
    "print(f\"Accuracy using inverse weighting: \\n\\t{np.round(100*knn.score(X_test, y_test), 4)}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9vWiTdlbR2Xh"
   },
   "source": [
    "## 2. (10%) Use the k-nearest neighbor algorithm (without distance weighting) for the [magic telescope](http://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope) problem\n",
    "\n",
    "- Use this [magic telescope training set](https://byu.instructure.com/courses/14142/files?preview=4660988) and this [magic telescope test set](https://byu.instructure.com/courses/14142/files?preview=4660989) \n",
    "\n",
    "### 2.1\n",
    "- Try it with k=3 and without normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 639,
   "metadata": {
    "id": "4SSoasDQSKXb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using no inverse weighting, and no normalization: \n",
      "\t80.8281%\n"
     ]
    }
   ],
   "source": [
    "# Load magic telescope data\n",
    "magic_data_train = arff.loadarff('magic_telescope_train.arff')\n",
    "magic_df_train = pd.DataFrame(magic_data_train[0])\n",
    "\n",
    "features_train = list(magic_df_train.columns)\n",
    "X_train = magic_df_train[features_train[0:-1]]\n",
    "y_train = magic_df_train[features_train[-1]]\n",
    "\n",
    "magic_data_test = arff.loadarff('magic_telescope_test.arff')\n",
    "magic_df_test = pd.DataFrame(magic_data_test[0])\n",
    "\n",
    "features_test = list(magic_df_test.columns)\n",
    "X_test = magic_df_test[features_test[0:-1]]\n",
    "y_test = magic_df_test[features_test[-1]]\n",
    "# Train/Predict without normalization\n",
    "\n",
    "knn = KNNClassifier(K = 3, weight_type = \"no_weight\")\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Accuracy using no inverse weighting, and no normalization: \\n\\t{np.round(100*knn.score(X_test, y_test), 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2\n",
    "- Try it with k=3 and with normalization (input features normalized between 0 and 1). Use the normalization formula (x-xmin)/(xmax-xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy using no inverse weighting, and normalization: \n",
      "\t81.5782%\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict with normalization\n",
    "knn = KNNClassifier(K = 3, weight_type = \"no_weight\")\n",
    "knn.fit(X_train, y_train, normalize = True)\n",
    "\n",
    "print(f\"Accuracy using no inverse weighting, and normalization: \\n\\t{np.round(100*knn.score(X_test, y_test), 4)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss the accuracy results of using normalized data vs. unnormalized data*\n",
    "\n",
    "Here, with the same K value, accuracy increased slightly after normalizing data. This indicates that there were a few outliers \"skewing\" the results, and that after normalizing, have less of an effect on accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3\n",
    "\n",
    "- Using your normalized data, create one graph with classification accuracy on the test set over k values. \n",
    "    - Use odd values of k from 1 to 15.\n",
    "- As a rough sanity check, typical knn accuracies for the magic telescope data set are 75-85%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Predict with normalization using k=1,3,...,15\n",
    "k_vals = [2*i + 1 for i in range(8)]\n",
    "accuracy_vals = []\n",
    "for k in k_vals:\n",
    "    knn = KNNClassifier(K = k, weight_type = \"no_weight\")\n",
    "    knn.fit(X_train, y_train, normalize = True)\n",
    "    accuracy_vals.append(100*knn.score(X_test, y_test))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Accuracy')"
      ]
     },
     "execution_count": 490,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph classification accuracy over k\n",
    "plt.figure(figsize = (12,4.5))\n",
    "plt.scatter(k_vals, accuracy_vals)\n",
    "plt.xticks(k_vals)\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the rest of the experiments use only normalized data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIRG42TgSR4x"
   },
   "source": [
    "## 3. (10%) Use the regression variation of your algorithm (without distance weighting) for the [housing price prediction](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html) problem.\n",
    "\n",
    "- Use this [housing training set](https://byu.instructure.com/courses/14142/files?preview=4660994) and this [housing test set](https://byu.instructure.com/courses/14142/files?preview=4660995).\n",
    "- Use Mean Square Error (MSE) on the test set as your accuracy metric for this case.\n",
    "    - Do not normalize regression output values\n",
    "- Graph MSE on the test set with odd values of k from 1 to 15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {
    "id": "KBGUn43ASiXW"
   },
   "outputs": [],
   "source": [
    "# Load housing price prediction data\n",
    "house_data_train = arff.loadarff('housing_train.arff')\n",
    "house_df_train = pd.DataFrame(house_data_train[0]).astype(float)\n",
    "# house_df_train[\"CHAS\"] = house_df_train[\"CHAS\"].astype(int)\n",
    "\n",
    "features_train = list(house_df_train.columns)\n",
    "X_train = house_df_train[features_train[0:-1]] # Data\n",
    "y_train = house_df_train[features_train[-1]] # Regression label\n",
    "\n",
    "house_data_test = arff.loadarff('housing_test.arff')\n",
    "house_df_test = pd.DataFrame(house_data_test[0]).astype(float)\n",
    "# house_df_test[\"CHAS\"] = house_df_test[\"CHAS\"].astype(int)\n",
    "\n",
    "features_test = list(house_df_test.columns)\n",
    "X_test = house_df_test[features_test[0:-1]]\n",
    "y_test = house_df_test[features_test[-1]]\n",
    "\n",
    "# Train/Predict using k=1,3,...,15\n",
    "k_vals = [2*i + 1 for i in range(8)]\n",
    "mse_vals = []\n",
    "for k in k_vals:\n",
    "    knn = KNNClassifier(K = k, weight_type = \"no_weight\")\n",
    "    knn.fit(X_train, y_train, normalize = True, regression = True)\n",
    "    mse_vals.append(knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graph MSE over k\n",
    "plt.figure(figsize = (12,4.5))\n",
    "plt.scatter(k_vals, mse_vals)\n",
    "plt.xticks(k_vals)\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v19fpixqTe-7"
   },
   "source": [
    "## 4. (15%) Repeat your experiments for magic telescope and housing using distance-weighted (inverse of distance squared) voting and discuss your results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Magic Telescope Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {
    "id": "ZCPFUAGTS2sX"
   },
   "outputs": [],
   "source": [
    "# Train/Predict magic telescope using distance-weighted voting\n",
    "magic_data_train = arff.loadarff('magic_telescope_train.arff')\n",
    "magic_df_train = pd.DataFrame(magic_data_train[0])\n",
    "\n",
    "features_train = list(magic_df_train.columns)\n",
    "X_train = magic_df_train[features_train[0:-1]]\n",
    "y_train = magic_df_train[features_train[-1]]\n",
    "\n",
    "magic_data_test = arff.loadarff('magic_telescope_test.arff')\n",
    "magic_df_test = pd.DataFrame(magic_data_test[0])\n",
    "\n",
    "features_test = list(magic_df_test.columns)\n",
    "X_test = magic_df_test[features_test[0:-1]]\n",
    "y_test = magic_df_test[features_test[-1]]\n",
    "\n",
    "k_vals = [2*i + 1 for i in range(8)]\n",
    "accuracy_vals = []\n",
    "for k in k_vals:\n",
    "    knn = KNNClassifier(K = k, weight_type = \"inverse_distance\")\n",
    "    knn.fit(X_train, y_train, normalize = True)\n",
    "    accuracy_vals.append(100*knn.score(X_test, y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,4.5))\n",
    "plt.scatter(k_vals, accuracy_vals)\n",
    "plt.xticks(k_vals)\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Housing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Predict housing using distance-weighted voting\n",
    "# Load housing price prediction data\n",
    "house_data_train = arff.loadarff('housing_train.arff')\n",
    "house_df_train = pd.DataFrame(house_data_train[0]).astype(float)\n",
    "# house_df_train[\"CHAS\"] = house_df_train[\"CHAS\"].astype(int)\n",
    "\n",
    "features_train = list(house_df_train.columns)\n",
    "X_train = house_df_train[features_train[0:-1]] # Data\n",
    "y_train = house_df_train[features_train[-1]] # Regression label\n",
    "\n",
    "house_data_test = arff.loadarff('housing_test.arff')\n",
    "house_df_test = pd.DataFrame(house_data_test[0]).astype(float)\n",
    "# house_df_test[\"CHAS\"] = house_df_test[\"CHAS\"].astype(int)\n",
    "\n",
    "features_test = list(house_df_test.columns)\n",
    "X_test = house_df_test[features_test[0:-1]]\n",
    "y_test = house_df_test[features_test[-1]]\n",
    "\n",
    "# Train/Predict using k=1,3,...,15\n",
    "k_vals = [2*i + 1 for i in range(8)]\n",
    "mse_vals = []\n",
    "for k in k_vals:\n",
    "    knn = KNNClassifier(K = k, weight_type = \"inverse_distance\")\n",
    "    knn.fit(X_train, y_train, normalize = True, regression = True)\n",
    "    mse_vals.append(knn.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x324 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,4.5))\n",
    "plt.scatter(k_vals, mse_vals)\n",
    "plt.xticks(k_vals)\n",
    "plt.xlabel(\"K value\")\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Discuss your results*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. (10%) Use the k-nearest neighbor algorithm to solve the [credit-approval](https://archive.ics.uci.edu/ml/datasets/Credit+Approval) (credit-a) problem.\n",
    "\n",
    "- Use this [credit approval dataset](https://byu.instructure.com/courses/14142/files?preview=4660998)\n",
    "    - Use a 70/30 split of the data for the training/test set\n",
    "- Note that this set has both continuous and nominal attributes, together with don’t know values. \n",
    "- Implement and justify a distance metric which supports continuous, nominal, and don’t know attribute values\n",
    "    - You need to handle don't knows with the distance metric, not by imputing a value.\n",
    "    - More information on distance metrics can be found [here](https://www.jair.org/index.php/jair/article/view/10182/24168).\n",
    "- Use your own choice for k.\n",
    "- As a rough sanity check, typical knn accuracies for the credit data set are 70-80%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with k = 6: 0.8309178743961353\n"
     ]
    }
   ],
   "source": [
    "# Load dataset and split into train/test sets\n",
    "credit_data = arff.loadarff('credit_approval.arff')\n",
    "credit_df = pd.DataFrame(credit_data[0])\n",
    "\n",
    "features = list(credit_df.columns)\n",
    "X = credit_df[features[0:-1]]\n",
    "y = credit_df[features[-1]] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Train/Predict credit-approval\n",
    "\n",
    "knn = KNNClassifier(K = 6, weight_type = \"inverse_distance\", metric = \"custom\")\n",
    "knn.fit(X_train, y_train, normalize = False, regression = False)\n",
    "print(f\"Accuracy with k = 6: {knn.score(X_test, y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Explain and justify your distance metric*\n",
    "\n",
    "My distance metric adds a 1 to the norm if a single None value is encounterd. If a bytes value is encountered, then I make sure the values are not equal, then add a 1 to the norm.\\\n",
    "Finally, if both values are floats and are not equal to each other, I normalize each one and take the 2-norm (euclidian distance). \\\n",
    "This metric works because often a none value is compared to a int or float value and since we have no idea how far away those points are from each other, we choose 1. 1 is not very far nor is it very close when considering how close the float values are to each other. \\\n",
    "I chose k = 6 as that gave me the highest accuracy. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oBBmeNQ7jvcQ"
   },
   "source": [
    "## 6. (15%) Use the scikit's KNN Classifier on magic telescope and KNN Regressor on housing and compare your results.\n",
    "\n",
    "- Try out different hyperparameters to see how well you can do. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {
    "id": "OFQv70W2VyqJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With weights set to uniform, and K = 3, and p = 2, accuracy is 0.8082808280828083\n",
      "With weights set to distance, and K = 3, and p = 2, accuracy is 0.8094809480948095\n",
      "With weights set to uniform, and K = 3, and p = 3, accuracy is 0.8052805280528053\n",
      "With weights set to distance, and K = 3, and p = 3, accuracy is 0.8058805880588059\n",
      "With weights set to uniform, and K = 3, and p = 4, accuracy is 0.804080408040804\n",
      "With weights set to distance, and K = 3, and p = 4, accuracy is 0.8052805280528053\n",
      "With weights set to uniform, and K = 5, and p = 2, accuracy is 0.8136813681368137\n",
      "With weights set to distance, and K = 5, and p = 2, accuracy is 0.8166816681668166\n",
      "With weights set to uniform, and K = 5, and p = 3, accuracy is 0.8120312031203121\n",
      "With weights set to distance, and K = 5, and p = 3, accuracy is 0.8147314731473148\n",
      "With weights set to uniform, and K = 5, and p = 4, accuracy is 0.8093309330933093\n",
      "With weights set to distance, and K = 5, and p = 4, accuracy is 0.8115811581158116\n",
      "With weights set to uniform, and K = 7, and p = 2, accuracy is 0.8156315631563157\n",
      "With weights set to distance, and K = 7, and p = 2, accuracy is 0.8211821182118212\n",
      "With weights set to uniform, and K = 7, and p = 3, accuracy is 0.8121812181218122\n",
      "With weights set to distance, and K = 7, and p = 3, accuracy is 0.8162316231623162\n",
      "With weights set to uniform, and K = 7, and p = 4, accuracy is 0.8099309930993099\n",
      "With weights set to distance, and K = 7, and p = 4, accuracy is 0.8135313531353136\n",
      "With weights set to uniform, and K = 9, and p = 2, accuracy is 0.8181818181818182\n",
      "With weights set to distance, and K = 9, and p = 2, accuracy is 0.8220822082208221\n",
      "With weights set to uniform, and K = 9, and p = 3, accuracy is 0.8166816681668166\n",
      "With weights set to distance, and K = 9, and p = 3, accuracy is 0.8196819681968197\n",
      "With weights set to uniform, and K = 9, and p = 4, accuracy is 0.813981398139814\n",
      "With weights set to distance, and K = 9, and p = 4, accuracy is 0.8172817281728173\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict magic telescope using scikit's KNN\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "magic_data_train = arff.loadarff('magic_telescope_train.arff')\n",
    "magic_df_train = pd.DataFrame(magic_data_train[0])\n",
    "\n",
    "features_train = list(magic_df_train.columns)\n",
    "X_train = magic_df_train[features_train[0:-1]]\n",
    "y_train = le.fit_transform(magic_df_train[features_train[-1]])\n",
    "\n",
    "magic_data_test = arff.loadarff('magic_telescope_test.arff')\n",
    "magic_df_test = pd.DataFrame(magic_data_test[0])\n",
    "\n",
    "features_test = list(magic_df_test.columns)\n",
    "X_test = magic_df_test[features_test[0:-1]]\n",
    "y_test = le.fit_transform(magic_df_test[features_test[-1]])\n",
    "\n",
    "weights_vals = [\"uniform\", \"distance\"]\n",
    "p_vals = [2,3,4]\n",
    "neigh_vals = [3,5,7,9]\n",
    "for k in neigh_vals:\n",
    "    for p in p_vals:\n",
    "        for weight in weights_vals:\n",
    "            neigh = KNeighborsClassifier(n_neighbors=k, weights = weight, p = p)\n",
    "            neigh.fit(X_train, y_train)\n",
    "            print(f\"With weights set to {weight}, and K = {k}, and p = {p}, accuracy is {neigh.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using distance weighting, k = 9 and p = 2, we get the best accuracy. k = 7 is a close second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With weights set to uniform, and K = 3, and p = 2, R^2 is 0.3089347485187751\n",
      "With weights set to distance, and K = 3, and p = 2, R^2 is 0.3114920892272527\n",
      "With weights set to uniform, and K = 3, and p = 3, R^2 is 0.22292245846883407\n",
      "With weights set to distance, and K = 3, and p = 3, R^2 is 0.23621892451869952\n",
      "With weights set to uniform, and K = 3, and p = 4, R^2 is 0.21595385172966386\n",
      "With weights set to distance, and K = 3, and p = 4, R^2 is 0.2277616504983757\n",
      "With weights set to uniform, and K = 5, and p = 2, R^2 is 0.25491902354492035\n",
      "With weights set to distance, and K = 5, and p = 2, R^2 is 0.2739381978953438\n",
      "With weights set to uniform, and K = 5, and p = 3, R^2 is 0.17347095770627008\n",
      "With weights set to distance, and K = 5, and p = 3, R^2 is 0.2062744711906369\n",
      "With weights set to uniform, and K = 5, and p = 4, R^2 is 0.17666224642779838\n",
      "With weights set to distance, and K = 5, and p = 4, R^2 is 0.20564006163348414\n",
      "With weights set to uniform, and K = 7, and p = 2, R^2 is 0.2979443003218095\n",
      "With weights set to distance, and K = 7, and p = 2, R^2 is 0.3049889045804747\n",
      "With weights set to uniform, and K = 7, and p = 3, R^2 is 0.22878778243746356\n",
      "With weights set to distance, and K = 7, and p = 3, R^2 is 0.24405480005241442\n",
      "With weights set to uniform, and K = 7, and p = 4, R^2 is 0.24452413803197226\n",
      "With weights set to distance, and K = 7, and p = 4, R^2 is 0.2542113242596583\n",
      "With weights set to uniform, and K = 9, and p = 2, R^2 is 0.330411036434183\n",
      "With weights set to distance, and K = 9, and p = 2, R^2 is 0.3430528009175514\n",
      "With weights set to uniform, and K = 9, and p = 3, R^2 is 0.2885487958523234\n",
      "With weights set to distance, and K = 9, and p = 3, R^2 is 0.3079244131103188\n",
      "With weights set to uniform, and K = 9, and p = 4, R^2 is 0.29521386488168866\n",
      "With weights set to distance, and K = 9, and p = 4, R^2 is 0.30797357847511053\n"
     ]
    }
   ],
   "source": [
    "# Train/Predict housing using scikit's KNN\n",
    "house_data_train = arff.loadarff('housing_train.arff')\n",
    "house_df_train = pd.DataFrame(house_data_train[0]).astype(float)\n",
    "\n",
    "features_train = list(house_df_train.columns)\n",
    "X_train = house_df_train[features_train[0:-1]] # Data\n",
    "y_train = house_df_train[features_train[-1]] # Regression label\n",
    "\n",
    "house_data_test = arff.loadarff('housing_test.arff')\n",
    "house_df_test = pd.DataFrame(house_data_test[0]).astype(float)\n",
    "\n",
    "features_test = list(house_df_test.columns)\n",
    "X_test = house_df_test[features_test[0:-1]]\n",
    "y_test = house_df_test[features_test[-1]]\n",
    "\n",
    "\n",
    "weights_vals = [\"uniform\", \"distance\"]\n",
    "p_vals = [2,3,4]\n",
    "neigh_vals = [3,5,7,9]\n",
    "for k in neigh_vals:\n",
    "    for p in p_vals:\n",
    "        for weight in weights_vals:\n",
    "            neigh = KNeighborsRegressor(n_neighbors=k, weights = weight, p = p)\n",
    "            neigh.fit(X_train, y_train)\n",
    "            print(f\"With weights set to {weight}, and K = {k}, and p = {p}, R^2 is {neigh.score(X_test, y_test)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqSFAXwlk3Ms"
   },
   "source": [
    "*Report your comparison*\n",
    "\n",
    "Clearly the classifier on magic telescope is much more accurate. However, it should be noted that the score metric on the regressor is neither accuracy nor MSE, it's rather an $R^2$ score. In other words, this $R^2$ score says how much variance can be explained by the data. Since this is fairly close to 0, it's safe to say that the \"accuracy\" is also not great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTlK-kijk8Mg"
   },
   "source": [
    "## 7. (optional 5% extra credit): For the best value of k for any one of the datasets, implement a reduction algorithm that removes data points in some rational way such that performance does not drop too drastically on the test set given the reduced training set.\n",
    "\n",
    "- Compare your performance on the test set for the reduced and non-reduced versions and give the number (and percentage) of training examples removed from the original training set. How well does your reduction algorithm work?\n",
    "    - Note that performance for magic telescope is classification accuracy and for housing it is mean squared error.\n",
    "    - Magic Telescope has about 12,000 instances and if you use a leave one out style of testing for your data set reduction, then your algorithm will run slow since that is n2 at each step.\n",
    "    - If you wish, you may use a random subset of 2,000 of the magic telescope instances.\n",
    "    - Examples of reduction techniques include: (a) leave-one-out reduction - Drop instance if it would still be classified correctly, (b) growth algorithm - Only add instance if it is not already classified correctly, (c) just keep central points, (d) just keep border points, etc. (see Wilson, D. R. and Martinez, T. R., Reduction Techniques for Exemplar-Based Learning Algorithms, Machine Learning Journal, vol. 38, no. 3, pp. 257-286, 2000)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "lab 1 - perceptron",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
